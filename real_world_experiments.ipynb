{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76cda3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximize reproducibility: set seed with minimal imports\n",
    "# just a seed\n",
    "seed = 431136\n",
    "import os\n",
    "\n",
    "# verbosity\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "# reproducibility\n",
    "# https://github.com/NVIDIA/framework-determinism\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(seed)\n",
    "rng_r = random.Random(seed + 1)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(seed + 2)\n",
    "rng_np = np.random.default_rng(seed + 3)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(seed + 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a8c6c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.display import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# from posthoceval.explainers import KernelSHAPExplainer\n",
    "# from posthoceval.explainers import MAPLEExplainer\n",
    "from posthoceval.explainers import *\n",
    "\n",
    "from posthoceval.expl_utils import standardize_effect\n",
    "from posthoceval.models.gam import MultiClassLogisticGAM\n",
    "from posthoceval.models.gam import LinearGAM\n",
    "from posthoceval.models.gam import T\n",
    "from posthoceval.models.dnn import AdditiveDNN\n",
    "from posthoceval.models.cnn import AdditiveCNN\n",
    "from posthoceval.transform import Transformer\n",
    "from posthoceval.utils import nonexistent_filename\n",
    "from posthoceval.datasets import COMPASDataset\n",
    "from posthoceval.datasets import BostonDataset\n",
    "from posthoceval.datasets import HELOCDataset\n",
    "from posthoceval.datasets import TinyMNISTDataset\n",
    "from posthoceval.models.term_util import generate_terms\n",
    "from posthoceval.viz import gather_viz_data\n",
    "from posthoceval import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84906cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(\n",
    "    # context='paper',\n",
    "    context='notebook',\n",
    "    style='ticks',\n",
    "    font_scale=1,  # 2.25,\n",
    "    color_codes=True,\n",
    "    # palette=sns.color_palette('pastel'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32852243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpl_backend(backend='inline'):\n",
    "    rc = plt.rcParams.copy()\n",
    "    # backend = plt.get_backend()\n",
    "    %matplotlib $backend\n",
    "    \n",
    "mpl_inline = lambda: mpl_backend('inline')\n",
    "mpl_qt = lambda: mpl_backend('qt')\n",
    "mpl_notebook = lambda: mpl_backend('notebook')\n",
    "# valid strings are ['GTK3Agg', 'GTK3Cairo', 'MacOSX', 'nbAgg', 'Qt4Agg',\n",
    "# 'Qt4Cairo', 'Qt5Agg', 'Qt5Cairo', 'TkAgg', 'TkCairo', 'WebAgg', 'WX',\n",
    "# 'WXAgg', 'WXCairo', 'agg', 'cairo', 'pdf', 'pgf', 'ps', 'svg', 'template']\n",
    "# mpl_backend('nbagg')\n",
    "mpl_backend('inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "146e1e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00b31a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples     = 27918\n",
      "Input Shape = (12, 10, 1)\n",
      "Task        = classification\n"
     ]
    }
   ],
   "source": [
    "# TODO!!! compas-classification...\n",
    "dataset_name = 'mnist'\n",
    "\n",
    "if dataset_name == 'synthetic':\n",
    "    raise NotImplementedError\n",
    "    task = 'regression'\n",
    "\n",
    "    # import numpy\n",
    "    # X = np.random.rand(1000, 8) / 4\n",
    "    # x1, x2, x3, x4, x5, x6, x7, x8 = X.T\n",
    "    # y = (x1 ** 2 + x5 ** 2 + x5 * numpy.log(x1 + x2) +\n",
    "    #      x7 * numpy.select([numpy.greater(x2, numpy.sinc(x1 / numpy.pi)),\n",
    "    #                         True],\n",
    "    #                        [numpy.asarray(x2 ** (-1.0)).astype(numpy.bool),\n",
    "    #                         numpy.asarray(numpy.sinc(x1 / numpy.pi) ** (-1.0)\n",
    "    #                                       ).astype(numpy.bool)],\n",
    "    #                        default=numpy.nan) + (\n",
    "    #              x1 * abs(x7) + x5) ** 3 + numpy.exp(x7) + numpy.exp(\n",
    "    #             (x1 + x2) / x5) + numpy.sin(numpy.log(x2)))\n",
    "\n",
    "    # X = np.random.randn(1000, 4)\n",
    "    # x1, x2, x3, x4 = X.T\n",
    "    # x1 = np.abs(x1)\n",
    "    # x2 = np.abs(x2)\n",
    "    # y = x1 ** (1 / 4) + np.sqrt(x2) + np.exp(x3 / 2) + np.abs(x4) + np.tan(\n",
    "    #     x4) / x1 ** 2\n",
    "\n",
    "    # X = np.random.randn(1000, 2)\n",
    "    # y = X[:, 0] ** 9 + np.tan(X[:, 1]) + np.abs(X[:, 0] / X[:, 1] ** 2)\n",
    "\n",
    "    # X = np.random.randn(1000, 400)\n",
    "    # y = np.exp(np.random.randn(len(X)))\n",
    "\n",
    "    # X[:, 1] = X[:, 0] / 2\n",
    "    # X[:, 2] = X[:, 1] + 1\n",
    "    # X[:, 3] = X[:, 2] * 2.6\n",
    "    # y = (np.sin(X[:, 0] ** 3) + np.maximum(X[:, 1], 0)\n",
    "    #     - np.sin(X[:, 2]) / X[:, 2] + 2 * X[:, 3])\n",
    "\n",
    "    feature_names = [*range(X.shape[1])]\n",
    "elif dataset_name == 'compas':\n",
    "    dataset_cls = COMPASDataset\n",
    "elif dataset_name == 'heloc':\n",
    "    dataset_cls = HELOCDataset\n",
    "elif dataset_name == 'boston':\n",
    "    dataset_cls = BostonDataset\n",
    "elif dataset_name == 'mnist':\n",
    "    dataset_cls = TinyMNISTDataset\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "    task = 'classification'\n",
    "    # dataset = datasets.load_iris()\n",
    "    # dataset = datasets.load_breast_cancer()\n",
    "    dataset = datasets.load_wine()\n",
    "\n",
    "    X = dataset.data\n",
    "    y = dataset.target\n",
    "\n",
    "# load dataset\n",
    "dataset_orig = dataset_cls()\n",
    "\n",
    "# transform data\n",
    "transformer = Transformer()\n",
    "dataset = transformer.fit_transform(dataset_orig)\n",
    "\n",
    "# extract data\n",
    "task = dataset.task\n",
    "X = dataset.X\n",
    "y = dataset.y\n",
    "feature_names = dataset.feature_names\n",
    "input_shape = dataset.input_shape\n",
    "n_features = dataset.n_features\n",
    "\n",
    "print(f'Samples     = {len(X)}')\n",
    "print(f'Input Shape = {input_shape}')\n",
    "print(f'Task        = {task}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32125839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "if len(input_shape) > 1:\n",
    "    model_type = 'cnn'\n",
    "else:\n",
    "    model_type = 'gam'\n",
    "    # model_type = 'dnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb6eaadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put together terms\n",
    "max_order = 2\n",
    "min_order = 1\n",
    "\n",
    "if dataset_name == 'heloc':\n",
    "    n_main = n_features - 10\n",
    "    desired_interactions = [(1, 2), (10, 12), (15, 18), (7, 11)]\n",
    "elif dataset_name == 'boston':\n",
    "    desired_interactions = [(1, 2)]\n",
    "    n_main = n_features\n",
    "elif dataset_name == 'compas':\n",
    "    desired_interactions = [(5, 10), (2, 8)]  # TODO....\n",
    "    n_main = n_features\n",
    "else:\n",
    "    desired_interactions = []\n",
    "    n_main = n_features\n",
    "\n",
    "n_interact = None if desired_interactions else None\n",
    "\n",
    "# current interact plots use this: LIME, MAPLE\n",
    "# desired_interactions = [(1, 2)]\n",
    "\n",
    "# features 8 & 9 correlate in Boston dataset\n",
    "# desired_interactions = [(8, 0, 1), (2, 8), (2, 9)]\n",
    "\n",
    "terms = generate_terms(\n",
    "    n_features=n_features,\n",
    "    n_main=n_main,\n",
    "    n_interact=n_interact,\n",
    "    desired_interactions=desired_interactions,\n",
    "    min_order=min_order,\n",
    "    max_order=max_order,\n",
    "    seed=rng_np,\n",
    ")\n",
    "# terms = [T.te(0, 1), T.te(2, 3), T.s(0, n_splines=50)]\n",
    "# terms = [T.te(0, 1), T.te(1, 3, n_splines=5), T.s(2, n_splines=50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bfea220",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ignoring terms\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 32s 32s/step - loss: 7.2492\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.1464\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.0671\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.0042\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.9491\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.8963\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.8421\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.7852\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.7260\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.6658\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.6058\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.5469\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.4899\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.4348\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.3813\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.3284\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.2754\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.2220\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.1684\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.1149\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.0618\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.0094\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.9576\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.9067\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.8566\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.8072\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.7583\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.7096\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.6609\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.6123\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.5641\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.5166\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.4698\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.4237\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.3782\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.3331\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.2883\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.2437\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.1995\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.1556\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.1123\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.0696\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.0274\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4.9856\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4.9442\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4.9031\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4.8623\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4.8219\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4.7820\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4.7425\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "if model_type == 'dnn' or model_type == 'cnn':\n",
    "    callback = EarlyStopping(monitor='loss', mode='min', patience=5,\n",
    "                             restore_best_weights=True)\n",
    "    optimizer = Adam(learning_rate=1e-3)\n",
    "    fit_kwargs = {'epochs': 1 if DEBUG else 50, 'batch_size': len(X),\n",
    "                  'callbacks': [callback], 'optimizer': optimizer}\n",
    "else:\n",
    "    fit_kwargs = {}\n",
    "\n",
    "# TODO: factor terms for categoricals in GAM?\n",
    "# TODO: embed categoricals in NN?\n",
    "\n",
    "if model_type == 'dnn':\n",
    "    model = AdditiveDNN(\n",
    "        terms=terms,\n",
    "        task=task,\n",
    "        symbol_names=feature_names,\n",
    "        activation='relu',\n",
    "    )\n",
    "elif model_type == 'cnn':\n",
    "    print('ignoring terms')\n",
    "    model = AdditiveCNN(\n",
    "        task=task,\n",
    "        input_shape=input_shape,\n",
    "        symbol_names=feature_names,\n",
    "        activation='relu',\n",
    "    )\n",
    "elif model_type == 'gam':\n",
    "    if task == 'classification':\n",
    "        model = MultiClassLogisticGAM(symbol_names=feature_names, terms=terms)\n",
    "    else:\n",
    "        model = LinearGAM(symbol_names=feature_names, terms=terms)\n",
    "else:\n",
    "    raise NotImplementedError(model_type)\n",
    "\n",
    "model.fit(X, y, **fit_kwargs)\n",
    "\n",
    "if model_type == 'dnn' or model_type == 'cnn':\n",
    "    model.plot_model(nonexistent_filename(f'{model_type}.png'),\n",
    "                     show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ca10fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_only_this_many = 10 if DEBUG else min(len(X), (10 if dataset_name == 'mnist' else 250))\n",
    "\n",
    "explain_only_this_many = min(explain_only_this_many, len(X))\n",
    "sample_idxs_all = np.arange(len(X))\n",
    "sample_idxs = rng_np.choice(sample_idxs_all,\n",
    "                            size=explain_only_this_many, replace=False)\n",
    "X_subset = X[sample_idxs]\n",
    "y_subset = y[sample_idxs]\n",
    "\n",
    "true_contribs = model.feature_contributions(X_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4958bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_array = [\n",
    "    #('VanillaGradients', VanillaGradientsExplainer),\n",
    "    #('VanillaGradients-Smooth', VanillaGradientsExplainer.smooth_grad),\n",
    "    #('GradientsXInputs', GradientsXInputsExplainer),\n",
    "    #('GradientsXInputs-Smooth', GradientsXInputsExplainer.smooth_grad),\n",
    "    #('IntegratedGradients', IntegratedGradientsExplainer),\n",
    "    #('IntegratedGradients-Smooth', IntegratedGradientsExplainer.smooth_grad),\n",
    "    #('Occlusion', OcclusionExplainer),\n",
    "    #('XRAI', XRAIExplainer),\n",
    "    #('XRAI-Smooth', XRAIExplainer.smooth_grad),\n",
    "    #('BlurIG', BlurIntegratedGradientsExplainer),\n",
    "    #('BlurIG-Smooth', BlurIntegratedGradientsExplainer.smooth_grad),\n",
    "    ('PDP', PDPExplainer),\n",
    "    ('LIME', LIMEExplainer),\n",
    "    ('SHAP', KernelSHAPExplainer),\n",
    "]\n",
    "if not dataset_orig.categorical_features:\n",
    "    explainer_array.append(('SHAPR', SHAPRExplainer))\n",
    "if task == 'regression':\n",
    "    explainer_array.extend([\n",
    "        ('MAPLE', MAPLEExplainer),\n",
    "        # ('PDP', PDPExplainer),\n",
    "    ])\n",
    "\n",
    "# TODO: feature_contributions() --> explain()\n",
    "# TODO: explain() --> ExplainerMixin (for both models and explainers)\n",
    "\n",
    "pred_contribs_map = {}\n",
    "pred_y_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77e1d588",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explaining model using PDP\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-136481643ccb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Explaining model using'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplainer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# fit full dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     pred_contribs, y_pred = explainer.feature_contributions(\n\u001b[1;32m     15\u001b[0m         X_subset, as_dict=True, return_predictions=True)\n",
      "\u001b[0;32m~/Projects/PostHocExplainerEvaluation/posthoceval/explainers/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, grouped_feature_names, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m# noinspection PyArgumentList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         self._fit(X=X, y=y, grouped_feature_names=grouped_feature_names,\n\u001b[0;32m--> 131\u001b[0;31m                   **kwargs)\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/PostHocExplainerEvaluation/posthoceval/explainers/global_/pdp.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, grouped_feature_names)\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mnum_grid_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_grid_points\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mgrid_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'percentile'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m             )\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'regression'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/PostHocExplainerEvaluation/venv/lib/python3.7/site-packages/pdpbox/pdp.py\u001b[0m in \u001b[0;36mpdp_isolate\u001b[0;34m(model, dataset, model_features, feature, num_grid_points, grid_type, percentile_range, grid_range, cust_grid_points, memory_limit, n_jobs, predict_kwds, data_transformer)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mfeature_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             feature=feature, feature_type=feature_type, predict_kwds=predict_kwds, data_transformer=data_transformer)\n\u001b[0;32m--> 156\u001b[0;31m         for feature_grid in feature_grids)\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/PostHocExplainerEvaluation/venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/PostHocExplainerEvaluation/venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/PostHocExplainerEvaluation/venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/PostHocExplainerEvaluation/venv/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/PostHocExplainerEvaluation/venv/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/PostHocExplainerEvaluation/venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/PostHocExplainerEvaluation/venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/PostHocExplainerEvaluation/venv/lib/python3.7/site-packages/pdpbox/pdp_calc_utils.py\u001b[0m in \u001b[0;36m_calc_ice_lines\u001b[0;34m(feature_grid, data, model, model_features, n_classes, feature, feature_type, predict_kwds, data_transformer, unit_test)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mgrid_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn_class\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_grid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mgrid_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/PostHocExplainerEvaluation/venv/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExtensionArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_dataclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/PostHocExplainerEvaluation/venv/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6949\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6950\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6951\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6952\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6953\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/PostHocExplainerEvaluation/venv/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/PostHocExplainerEvaluation/venv/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1020\u001b[0m       skip_on_eager=False) as name:\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       packed_begin, packed_end, packed_strides = (stack(begin), stack(end),\n\u001b[0m\u001b[1;32m   1023\u001b[0m                                                   stack(strides))\n\u001b[1;32m   1024\u001b[0m       if (packed_begin.dtype == dtypes.int64 or\n",
      "\u001b[0;32m~/Projects/PostHocExplainerEvaluation/venv/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/PostHocExplainerEvaluation/venv/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1399\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m       \u001b[0;31m# If the input is a constant list, it can be converted to a constant op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1402\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Input list contains non-constant tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/PostHocExplainerEvaluation/venv/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/PostHocExplainerEvaluation/venv/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/PostHocExplainerEvaluation/venv/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    337\u001b[0m                                          as_ref=False):\n\u001b[1;32m    338\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/PostHocExplainerEvaluation/venv/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[1;32m    264\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 265\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/PostHocExplainerEvaluation/venv/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m def _constant_impl(\n\u001b[0m\u001b[1;32m    269\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast):\n\u001b[1;32m    270\u001b[0m   \u001b[0;34m\"\"\"Implementation of constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# os.environ['R_HOME'] = '/afs/crc.nd.edu/x86_64_linux/r/R/3.6.2/gcc/4.8.5/bin/R'\n",
    "# del os.environ['R_HOME']\n",
    "# import sys\n",
    "# sys.path.append('/afs/crc.nd.edu/x86_64_linux/r/R/3.6.2/gcc/4.8.5/bin/')\n",
    "\n",
    "for expl_i, (explainer_name, explainer_cls) in enumerate(explainer_array):\n",
    "    if explainer_name in pred_contribs_map:\n",
    "        print('Skipping', explainer_name)\n",
    "        continue\n",
    "    print('Explaining model using', explainer_name)\n",
    "    explainer = explainer_cls(model, seed=seed, task=task)\n",
    "    explainer.fit(dataset)  # fit full dataset\n",
    "    pred_contribs, y_pred = explainer.feature_contributions(\n",
    "        X_subset, as_dict=True, return_predictions=True)\n",
    "\n",
    "    # store for later viz data generation\n",
    "    pred_contribs_map[explainer_name] = pred_contribs\n",
    "    pred_y_map[explainer_name] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffed508",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: import from viz and implement fully...\n",
    "# plot_fit()\n",
    "\n",
    "df, df_3d, contribs_df, err_dfs = gather_viz_data(\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    transformer=transformer,\n",
    "    true_contribs=true_contribs,\n",
    "    pred_contribs_map=pred_contribs_map,\n",
    "    dataset_sample_idxs=sample_idxs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7406671",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "col_wrap = 4\n",
    "\n",
    "if df is not None:\n",
    "    # from seaborn._core import unique_markers\n",
    "    \n",
    "    # if n_features > 12 or task == 'classification':\n",
    "    #     mpl_qt()\n",
    "    # else:\n",
    "    #     mpl_inline()\n",
    "    g = sns.relplot(\n",
    "        data=df,\n",
    "        x='Feature Value',\n",
    "        y='Contribution',\n",
    "        hue='Explainer',\n",
    "        style='Explainer',\n",
    "        # markers=unique_markers(len(explainer_array) + 1),\n",
    "        # col='class' if task == 'classification' else 'true_effect',\n",
    "        col='Class' if task == 'classification' else 'Match',\n",
    "        col_wrap=None if task == 'classification' else col_wrap,\n",
    "        # row='true_effect' if task == 'classification' else None,\n",
    "        row='Match' if task == 'classification' else None,\n",
    "        kind='scatter',\n",
    "        x_jitter=.08,  # for visualization purposes of nearby points\n",
    "        # scatter_kws=dict(alpha=.65),\n",
    "        alpha=.65,\n",
    "        facet_kws=dict(sharex=False, sharey=False),\n",
    "        # sharex=False, sharey=False\n",
    "    )\n",
    "    for ax in g.axes.flat:\n",
    "        title = ax.get_title()\n",
    "        ax.set_title(title.split(' = ', 1)[1])\n",
    "    g.tight_layout()\n",
    "    g.savefig(nonexistent_filename(f'contributions_grid_{model_type}.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c72fc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3d interaction plot time\n",
    "if df_3d is not None:\n",
    "\n",
    "    plt_x = 'Feature Value x'\n",
    "    plt_y = 'Feature Value y'\n",
    "    plt_z = 'Contribution'\n",
    "    plt_hue = 'Explainer'\n",
    "    plt_col = 'Match'\n",
    "\n",
    "    df_3d_grouped = df_3d.groupby(['Class', plt_col])\n",
    "\n",
    "    n_plots = len(df_3d_grouped)\n",
    "    n_rows = int(np.ceil(n_plots / col_wrap))\n",
    "    n_cols = min(col_wrap, n_plots)\n",
    "    figsize = plt.rcParams['figure.figsize']\n",
    "    figsize = (figsize[0] * n_cols, figsize[1] * n_rows)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "\n",
    "    for i, ((class_i, ax_title), group_3d) in enumerate(df_3d_grouped):\n",
    "        ax = fig.add_subplot(n_rows, n_cols, i + 1, projection='3d')\n",
    "\n",
    "        for hue_name, hue_df in group_3d.groupby(plt_hue):\n",
    "            ax.scatter(\n",
    "                hue_df[plt_x],\n",
    "                hue_df[plt_y],\n",
    "                hue_df[plt_z],\n",
    "                label=hue_name,\n",
    "                alpha=.5,\n",
    "            )\n",
    "        ax.set_xlabel(plt_x)\n",
    "        ax.set_ylabel(plt_y)\n",
    "        ax.set_zlabel(plt_z)\n",
    "\n",
    "        ax.set_title(ax_title)\n",
    "\n",
    "        if i == 0:\n",
    "            fig.legend(loc='center right')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(nonexistent_filename(\n",
    "        f'contributions_grid_interact_{model_type}.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab376ff9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "err_dfs['effectwise_err_agg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16c71da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "err_dfs['samplewise_err_agg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a516d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_effects(*effect_sets):\n",
    "    all_effects = []\n",
    "    for effects_set in zip(*effect_sets):\n",
    "        features = set()\n",
    "        for effects in effects_set:\n",
    "            for effect in effects:\n",
    "                features.update(effect)\n",
    "        all_effects.append(standardize_effect(tuple(features)))\n",
    "    return all_effects\n",
    "\n",
    "\n",
    "def effects_to_str(*effect_sets):\n",
    "    effect_strs = []\n",
    "    for effects_set in zip(*effect_sets):\n",
    "        features = set()\n",
    "        for effects in effects_set:\n",
    "            for effect in effects:\n",
    "                features.update(effect)\n",
    "        features = ' & '.join(standardize_effect(tuple(features)))\n",
    "        effect_strs.append(features)\n",
    "    return effect_strs\n",
    "\n",
    "\n",
    "def grab_expl_data(explanation):\n",
    "    contribs = contribs_df[(contribs_df['Explainer'] == explanation['Explainer']) &\n",
    "                           (contribs_df['Class'] == explanation['Class'])]\n",
    "    assert len(contribs) == 1\n",
    "    # get contribs for true/pred\n",
    "    contribs = contribs.iloc[0]\n",
    "    true_contribs = contribs['True Contribs']\n",
    "    pred_contribs = contribs['Pred Contribs']\n",
    "    # get attributions for effects\n",
    "    sample_idx = explanation['Sample Index']\n",
    "    # pred\n",
    "    sample_pred_contribs = pred_contribs.iloc[sample_idx]\n",
    "    pred_effects = sample_pred_contribs.keys()\n",
    "    pred_contribs = sample_pred_contribs.values\n",
    "    # true\n",
    "    sample_true_contribs = true_contribs.iloc[sample_idx]\n",
    "    true_effects = sample_true_contribs.keys()\n",
    "    true_contribs = sample_true_contribs.values\n",
    "    return pred_effects, pred_contribs, true_effects, true_contribs, sample_idx\n",
    "\n",
    "\n",
    "def plot_explanation(\n",
    "    explanation,\n",
    "    k=10,\n",
    "):\n",
    "    pred_effects, pred_contribs, true_effects, true_contribs, _ = grab_expl_data(explanation)\n",
    "    # map to readable strings\n",
    "    all_effects = effects_to_str(pred_effects, true_effects)\n",
    "    # grab top-k effects\n",
    "    sort_idx = np.argsort(np.abs(true_contribs))[-k:][::-1]\n",
    "    pred_contribs = pred_contribs[sort_idx]\n",
    "    true_contribs = true_contribs[sort_idx]\n",
    "    all_effects = np.asarray(all_effects)[sort_idx]\n",
    "    # set up DF for plotting\n",
    "    df_plot = pd.concat([\n",
    "        pd.DataFrame({\n",
    "            'Effect': all_effects,\n",
    "            'Explainer': 'True',\n",
    "            'Contribution': true_contribs,\n",
    "        }),\n",
    "        pd.DataFrame({\n",
    "            'Effect': all_effects,\n",
    "            'Explainer': explanation['Explainer'],\n",
    "            'Contribution': pred_contribs,\n",
    "        }),\n",
    "    ], ignore_index=True)\n",
    "    f, ax = plt.subplots()\n",
    "    sns.barplot(y='Effect', x='Contribution', hue='Explainer',\n",
    "                data=df_plot, ax=ax,\n",
    "                orient='h')\n",
    "    # ax.set_xscale('symlog')\n",
    "    f.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "def heatmap_explanation(\n",
    "    explanation,\n",
    "    shape,\n",
    "):\n",
    "    pred_effects, pred_contribs, true_effects, true_contribs, sample_idx = grab_expl_data(explanation)\n",
    "    all_effects = combine_effects(pred_effects, true_effects)\n",
    "    viz_data_true = np.zeros(n_features)\n",
    "    viz_data = np.zeros(n_features)\n",
    "    for j, effect in enumerate(all_effects):\n",
    "        idxs = [model.symbols.index(feat) for feat in effect]\n",
    "        viz_data[idxs] = pred_contribs[j]\n",
    "        viz_data_true[idxs] = true_contribs[j]\n",
    "\n",
    "    viz_data_true = viz_data_true.reshape(shape)\n",
    "    viz_data = viz_data.reshape(shape)\n",
    "    \n",
    "    f, ax = plt.subplots(1, 3)\n",
    "    ax = ax.flatten()\n",
    "    sns.heatmap(X_subset[sample_idx].squeeze(), ax=ax[0], cmap='gray',\n",
    "                square=True)\n",
    "    ax[0].set_title('Data')\n",
    "    \n",
    "    # f, ax = plt.subplots()\n",
    "    sns.heatmap(viz_data_true, ax=ax[1], cmap='coolwarm', square=True)\n",
    "    ax[1].set_title('True')\n",
    "    \n",
    "    # f, ax = plt.subplots()\n",
    "    sns.heatmap(viz_data, ax=ax[2], cmap='coolwarm', square=True)\n",
    "    ax[2].set_title('Explainer')\n",
    "    \n",
    "    f.tight_layout()\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7995b988",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "worst_by = 'root_mean_squared_error'\n",
    "\n",
    "# Top k worst effects per explainer\n",
    "df_effects = err_dfs['effectwise_err']\n",
    "df_effects = df_effects[df_effects['Metric'] == worst_by]\n",
    "for explainer_name, df_expl_effects in df_effects.groupby(['Explainer']):\n",
    "    k_f = min(k, len(df_expl_effects))\n",
    "    df_expl_effects = df_expl_effects.sort_values(by='Score', ascending=False)\n",
    "    print(f'{explainer_name} Top-{k_f} worst effects:')\n",
    "    display(df_expl_effects.iloc[:k_f])\n",
    "    print(f'{explainer_name} Top-{k_f} best effects:')\n",
    "    display(df_expl_effects.iloc[-k_f:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355f13a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "worst_by = 'cosine_distances'\n",
    "# worst_by = 'euclidean_distances'\n",
    "\n",
    "# Top k worst explanations per explainer\n",
    "df_effects = err_dfs['samplewise_err']\n",
    "df_effects = df_effects[df_effects['Metric'] == worst_by]\n",
    "for explainer_name, df_expl_effects in df_effects.groupby(['Explainer']):\n",
    "    k_f = min(k, len(df_expl_effects))\n",
    "    df_expl_effects = df_expl_effects.sort_values(by='Score', ascending=False)\n",
    "    print(f'{explainer_name} Top-{k_f} worst explanations:')\n",
    "    display(df_expl_effects.iloc[:k_f])\n",
    "    print(f'{explainer_name} Top-{k_f} best explanations:')\n",
    "    display(df_expl_effects.iloc[-k_f:])\n",
    "    for kk_f in [5, 10, 20, len(df_expl_effects)]:\n",
    "        if kk_f > len(df_expl_effects):\n",
    "            continue\n",
    "        tit_extra = '' if kk_f == len(df_expl_effects) else f' (top-{kk_f} effects)'\n",
    "        ax = plot_explanation(df_expl_effects.iloc[0], k=kk_f)\n",
    "        ax.set_title(f'{explainer_name} worst explanation{tit_extra}')\n",
    "        ax = plot_explanation(df_expl_effects.iloc[-1], k=kk_f)\n",
    "        ax.set_title(f'{explainer_name} best explanation{tit_extra}')\n",
    "    \n",
    "    if 2 <= len(input_shape) <= 3:\n",
    "        if len(input_shape) == 3:\n",
    "            if input_shape[2] != 1:\n",
    "                print(f'{input_shape} does not have unary channels, not implemented for viz!')\n",
    "                continue\n",
    "            else:\n",
    "                shape = input_shape[:2]\n",
    "        else:\n",
    "            shape = input_shape\n",
    "        f = heatmap_explanation(df_expl_effects.iloc[0], shape)\n",
    "        f.suptitle(f'{explainer_name} worst explanation')\n",
    "        f = heatmap_explanation(df_expl_effects.iloc[-1], shape)\n",
    "        f.suptitle(f'{explainer_name} best explanation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f913db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_model_subset = model.predict(X_subset)\n",
    "if task == 'classification':\n",
    "    acc = metrics.accuracy(y_subset, y_model_subset)\n",
    "    print(f'Model accuracy={acc * 100:.2f}')\n",
    "else:\n",
    "    err = metrics.rmse(y_subset, y_model_subset)\n",
    "    print(f'Model rmse={err:.3g}')\n",
    "\n",
    "perfs = []\n",
    "for explainer_name, y_pred_expl in pred_y_map.items():\n",
    "    if y_pred_expl is None:\n",
    "        print('Skipping', explainer_name, '(no predict() implementation)')\n",
    "        continue\n",
    "    if task == 'classification':\n",
    "        metric_name = 'accuracy'\n",
    "        y_pred_expl = np.argmax(y_pred_expl, axis=0)\n",
    "        score = acc = metrics.accuracy(y_model_subset, y_pred_expl)\n",
    "        print(f'{explainer_name} accuracy={acc * 100:.2f}')\n",
    "    else:\n",
    "        metric_name = 'rmse'\n",
    "        score = err = metrics.rmse(y_model_subset, y_pred_expl)\n",
    "        print(f'{explainer_name} rmse={err:.3g}')\n",
    "    perfs.append({'Explainer': explainer_name, 'Metric': metric_name, 'Score': score})\n",
    "perf_df = pd.DataFrame(perfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14578f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump all data to file for reproducing plotting etc.\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "out_dir = 'real_world_results'\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "\n",
    "now_str = datetime.now().isoformat(timespec='seconds').replace(':', '_')\n",
    "out_name = f'{dataset_name}_{model_type}_{task}_{now_str}.pkl'\n",
    "out_path = os.path.join(out_dir, out_name)\n",
    "\n",
    "with open(out_path, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'df': df,\n",
    "        'df_3d': df_3d,\n",
    "        'contribs_df': contribs_df,\n",
    "        'err_dfs': err_dfs,\n",
    "        'task': task,\n",
    "        'feature_names': feature_names,\n",
    "        'input_shape': input_shape,\n",
    "        'n_features': n_features,\n",
    "        'model_type': model_type,\n",
    "        'perf_df': perf_df,\n",
    "    }, f)\n",
    "\n",
    "print(out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "posthoceval",
   "language": "python",
   "name": "posthoceval"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
